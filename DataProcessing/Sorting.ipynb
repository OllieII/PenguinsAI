{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seconds_from_launch(game_state_str):\n",
    "    try:\n",
    "        return json.loads(game_state_str).get('seconds_from_launch', 0)\n",
    "    except json.JSONDecodeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\oguo2\\GitHub\\PenguinsAI\\RawData\\PENGUINS_20240101_to_20240131_df72162_events.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_then_launch(target_csv, output_name, output_status):\n",
    "    target_csv['seconds_from_launch'] = target_csv['game_state'].apply(extract_seconds_from_launch)\n",
    "    df_sorted = target_csv.sort_values(by=['session_id', 'index'])\n",
    "    if output_status:\n",
    "        df_sorted.to_csv(output_name, sep='\\t', index=False)\n",
    "    else:\n",
    "        return df_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = session_then_launch(df,\"Sorted_Jan\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'app_id', 'timestamp', 'event_name', 'event_data',\n",
       "       'event_source', 'app_version', 'app_branch', 'log_version', 'offset',\n",
       "       'user_id', 'user_data', 'game_state', 'index', 'seconds_from_launch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_event_starts(group, event_name):\n",
    "    mismatches = []\n",
    "    # Get indices of the specified event\n",
    "    event_indices = group[group['event_name'] == event_name].index\n",
    "    # Check each event occurrence\n",
    "    for idx in event_indices:\n",
    "        # If it's not the first event or if the previous 'session_id' is the same, it's a mismatch\n",
    "        if idx != group.index[0] and group.at[idx, 'session_id'] == group.at[idx - 1, 'session_id']:\n",
    "            mismatches.append(group.at[idx, 'session_id'])\n",
    "    return mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mismatches(df, event_name):\n",
    "    # Group by 'session_id' and apply the checking function for the specified event name\n",
    "    mismatched_sessions = df.groupby('session_id').apply(lambda g: check_event_starts(g, event_name))\n",
    "\n",
    "    # Flatten the list of mismatched sessions\n",
    "    mismatched_sessions = [item for sublist in mismatched_sessions for item in sublist]\n",
    "\n",
    "    # Print out the sessions with mismatches\n",
    "    if mismatched_sessions:\n",
    "        print(f\"The total of '{len(mismatched_sessions)}'following sessions have '{event_name}' events that do not match a change in 'session_id':\")\n",
    "        for session in mismatched_sessions:\n",
    "            print(session)\n",
    "    else:\n",
    "        print(f\"All '{event_name}' events match a change in 'session_id'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 'device_identifier' events match a change in 'session_id'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oguo2\\AppData\\Local\\Temp\\ipykernel_15228\\3782325686.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  mismatched_sessions = df.groupby('session_id').apply(lambda g: check_event_starts(g, event_name))\n"
     ]
    }
   ],
   "source": [
    "find_mismatches(df_sorted, 'device_identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['index']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['event_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lstm_input_format(df, fraction=1.0):\n",
    "    # Initialize the one-hot encoder for event names\n",
    "    valid_events = df['event_name'].unique()\n",
    "    event_encoder = OneHotEncoder()\n",
    "    event_encoder.fit(valid_events.reshape(-1, 1))\n",
    "\n",
    "    sessions = df['session_id'].unique()\n",
    "    all_sequences = []\n",
    "    all_labels = []\n",
    "\n",
    "    for session in sessions:\n",
    "        session_data = df[df['session_id'] == session].sort_values('timestamp')\n",
    "        \n",
    "        # Determine the label for the whole session before applying the fraction cut-off\n",
    "        label = 1 if 'egg_hatched' in session_data['event_name'].values or 'nest_complete' in session_data['event_name'].values else 0\n",
    "        \n",
    "        # Apply fraction cut-off\n",
    "        limit = int(len(session_data) * fraction)\n",
    "        session_data = session_data.head(limit)\n",
    "\n",
    "        sequence = []\n",
    "\n",
    "        for _, row in session_data.iterrows():\n",
    "            # Skip the 'egg_hatched' or 'nest_complete' events\n",
    "            if row['event_name'] in ['egg_hatched', 'nest_complete']:\n",
    "                continue\n",
    "\n",
    "            game_state = json.loads(row['game_state'])\n",
    "            features = [\n",
    "                game_state.get('posX', 0),\n",
    "                game_state.get('posY', 0),\n",
    "                game_state.get('posZ', 0),\n",
    "                game_state.get('rotW', 0),\n",
    "                game_state.get('rotX', 0),\n",
    "                game_state.get('rotY', 0),\n",
    "                game_state.get('rotZ', 0),\n",
    "                game_state.get('seconds_from_launch', 0)\n",
    "            ]\n",
    "            \n",
    "            event_encoded = event_encoder.transform([[row['event_name']]]).toarray()\n",
    "            features.extend(event_encoded.flatten().tolist())\n",
    "            sequence.append(features)\n",
    "        \n",
    "        if sequence:  # Add to the dataset only if there is data in the sequence\n",
    "            scaler = StandardScaler()\n",
    "            sequence = np.array(sequence)\n",
    "            sequence[:, :8] = scaler.fit_transform(sequence[:, :8])\n",
    "            all_sequences.append(sequence)\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return all_sequences, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequences_full, all_labels_full = convert_to_lstm_input_format(df=df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32696390658174096"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_labels_full.count(1))/len(all_labels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device( 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "def extract_fraction_of_sequences(all_sequences, fraction):\n",
    "    fraction_sequences = []\n",
    "    for sequence in all_sequences:\n",
    "        limit = int(len(sequence) * fraction)\n",
    "        fraction_sequence = sequence[:limit]\n",
    "        fraction_sequences.append(fraction_sequence)\n",
    "    return fraction_sequences\n",
    "def calculate_lengths(sequences_batch):\n",
    "    lengths = (sequences_batch != 0).sum(dim=2) # assuming the padding is zero, and the non-feature dimension is 2\n",
    "    lengths, sorted_idx = lengths.sort(descending=True)\n",
    "    return lengths.cpu(), sorted_idx.cpu() # ensure indices are on the CPU for use with data\n",
    "def binary_accuracy(preds, y):\n",
    "    # Round predictions to the closest integer (0 or 1)\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the batch\n",
    "        packed_input = pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, (ht, ct) = self.lstm(packed_input)\n",
    "        out = self.dropout(ht[-1])\n",
    "        return self.fc(out)\n",
    "    \n",
    "def sequences_to_padded_tensor(sequences):\n",
    "    # Padding each sequence to the length of the longest sequence in the batch\n",
    "    sequences_tensor = [torch.tensor(sequence) for sequence in sequences]\n",
    "    sequences_padded = pad_sequence(sequences_tensor, batch_first=True)\n",
    "    return sequences_padded.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([95, 1062, 38]) torch.Size([376, 1440, 38])\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n",
      "Batch Shape: torch.Size([32, 1440, 38]) torch.Size([32])\n",
      "Max sorted_idx: 1439 Batch Size: 32\n",
      "Index out of bounds detected.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 32 is out of bounds for dimension 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sequences_batch, labels_batch \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Move lengths to the same device\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     lengths, sorted_idx \u001b[38;5;241m=\u001b[39m calculate_lengths(sequences_batch)\n\u001b[1;32m---> 76\u001b[0m     sequences_batch \u001b[38;5;241m=\u001b[39m \u001b[43msequences_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     77\u001b[0m     labels_batch \u001b[38;5;241m=\u001b[39m labels_batch[sorted_idx]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     78\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m lengths\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 32 is out of bounds for dimension 0 with size 32"
     ]
    }
   ],
   "source": [
    "fractions = [i/10 for i in range(1, 11)]  # Fractions from 0.1 to 1.0\n",
    "accuracies = []\n",
    "\n",
    "for fraction in fractions:\n",
    "    # Process the data\n",
    "    sequences_fraction = extract_fraction_of_sequences(all_sequences_full, fraction)\n",
    "    labels_fraction = all_labels_full[:len(sequences_fraction)]\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sequences_fraction, labels_fraction, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Convert training and testing data to tensors\n",
    "    X_train_padded = sequences_to_padded_tensor(X_train)\n",
    "    X_test_padded = sequences_to_padded_tensor(X_test)\n",
    "    y_train_tensor = torch.tensor(y_train, device=device).float()\n",
    "    y_test_tensor = torch.tensor(y_test, device=device).float()\n",
    "\n",
    "    print(X_test_padded.shape, X_train_padded.shape)\n",
    "    # Create TensorDatasets and DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_padded, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_padded, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "\n",
    "    # Define the model, loss function, and optimizer\n",
    "    input_size = X_train_padded.size(2)  # Number of features\n",
    "    hidden_size = 64  # Can be tuned\n",
    "    num_layers = 1  # Can be tuned\n",
    "    num_classes = 1  # Binary classification\n",
    "\n",
    "    model = LSTMClassifier(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10  # Can be tuned\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        for i, (sequences_batch, labels_batch) in enumerate(train_loader):\n",
    "            print(\"Batch Shape:\", sequences_batch.shape, labels_batch.shape) \n",
    "\n",
    "            lengths, sorted_idx = calculate_lengths(sequences_batch)\n",
    "            print(\"Max sorted_idx:\", sorted_idx.max().item(), \"Batch Size:\", sequences_batch.size(0))  # Debug print\n",
    "\n",
    "            if sorted_idx.max() >= sequences_batch.size(0):\n",
    "                print(\"Index out of bounds detected.\")\n",
    "                continue\n",
    "\n",
    "            sequences_batch = sequences_batch[sorted_idx].to(device)\n",
    "            labels_batch = labels_batch[sorted_idx].to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequences_batch, lengths)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs.view(-1), labels_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 10 == 0:\n",
    "                acc = binary_accuracy(outputs.view(-1), labels_batch)\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    with torch.no_grad():\n",
    "        for sequences_batch, labels_batch in test_loader:\n",
    "            # Move lengths to the same device\n",
    "            lengths, sorted_idx = calculate_lengths(sequences_batch)\n",
    "            sequences_batch = sequences_batch[sorted_idx].to(device)\n",
    "            labels_batch = labels_batch[sorted_idx].to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(sequences_batch, lengths)\n",
    "            loss = criterion(outputs.view(-1), labels_batch)\n",
    "            test_loss += loss.item()\n",
    "            accuracy = binary_accuracy(outputs.view(-1), labels_batch)\n",
    "            total_accuracy += accuracy.item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_accuracy = total_accuracy / len(test_loader)\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_accuracy:.2f}')\n",
    "    accuracies.append(avg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
